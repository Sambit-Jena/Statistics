{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537841e7-1941-4036-b34a-b5c22e546250",
   "metadata": {},
   "source": [
    "## Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcccb16-0a51-413d-a9c7-49b5e6bbb50a",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare means between three or more groups. To ensure the validity of ANOVA results, several assumptions need to be met. Violations of these assumptions can lead to incorrect conclusions. The main assumptions for using ANOVA are:\n",
    "\n",
    "1. Independence: The observations within each group should be independent of each other. This means that the data points in one group should not be influenced by or related to the data points in another group. \n",
    "* For example, if we're comparing the performance of students from different schools, but students within the same school tend to have similar scores due to common teaching methods, the independence assumption may be violated.\n",
    "\n",
    "2. Normality: The residuals (the differences between observed values and predicted values) should be normally distributed within each group. \n",
    "* For example, if we're comparing the effectiveness of different treatments on a health outcome, and the residuals within each treatment group are not normally distributed, the validity of ANOVA results might be compromised.\n",
    "\n",
    "3. Homogeneity of Variance (Homoscedasticity): The variability of the data should be roughly the same across all groups. This means that the spread of data points around the group means should be consistent across groups. \n",
    "* For example, if we're comparing the yields of different crop treatments, and one treatment group has much higher variability in yields than the others, the assumption might be violated.\n",
    "\n",
    "###### Examples of violations that could impact the validity of ANOVA results:\n",
    "\n",
    "1. Outliers: Outliers can skew the distribution of residuals and affect the assumption of normality, leading to inaccurate ANOVA results. For instance, if one group has an unusually high or low value that doesn't align with the rest of the data, it could violate the normality assumption.\n",
    "\n",
    "2. Heteroscedasticity: If the variability of the data is different across groups, it can violate the assumption of homogeneity of variance. This might lead to unequal influence of groups on the overall ANOVA results. For example, if we're comparing the response times of different software systems, and one system consistently shows much higher variability in response times than the others, the assumption might be violated.\n",
    "\n",
    "3. Non-Normality: If the residuals within groups are not normally distributed, the results of ANOVA might not be accurate. For instance, if we're comparing the test scores of students from different classes, and the scores within one class are heavily skewed towards high values, it could violate the normality assumption.\n",
    "\n",
    "4. Correlation between Observations: If there's a correlation between observations in different groups, it can violate the independence assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422f926-4a5f-468d-a725-5eebad78d898",
   "metadata": {},
   "source": [
    "## Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8733d78-0bd9-424b-8c6b-bcbe30a2f4dc",
   "metadata": {},
   "source": [
    "1. One-Way ANOVA:\n",
    "This type of ANOVA is used when we have one independent variable with three or more levels (groups), and we want to determine if there are any significant differences in means among those groups. For example, if we are testing the effects of different doses of a drug (low, medium, high) on a certain health outcome, we would use a one-way ANOVA to analyze the differences in outcome means among the three dose groups.\n",
    "\n",
    "2. Two-Way ANOVA:\n",
    "Two-Way ANOVA is used when we have two independent variables (factors) and we want to understand how they both impact a dependent variable. This allows us to analyze main effects and interaction effects. For instance, if we are studying the effects of both gender and different teaching methods on student performance, a two-way ANOVA would be appropriate.\n",
    "\n",
    "3. Three-Way ANOVA:\n",
    "Three-Way ANOVA extends the concept of two-way ANOVA to three independent variables. It's used when we have three factors and we want to investigate their individual and combined effects on a dependent variable. This type of ANOVA is less common due to the increased complexity and difficulty in interpreting higher-order interactions. An example scenario might involve studying the effects of fertilizer type, temperature, and sunlight exposure on plant growth in a field of agriculture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa6a5d-70c5-42ed-bd0b-55be6c5ef9a2",
   "metadata": {},
   "source": [
    "## Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c77627-a1b5-4540-bdbf-8f4f7fceb19f",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the division of the total variability observed in the data into different components that can be attributed to specific sources of variation. Understanding this concept is crucial because it helps us quantify and understand the relative contributions of various factors to the variability in the data. It forms the foundation for interpreting ANOVA results and drawing meaningful conclusions about the differences between groups or the effects of different factors.\n",
    "\n",
    "In ANOVA, the total variability in the data is broken down into two main components:\n",
    "\n",
    "1. Between-Group Variability (Treatment Variability):\n",
    "This component of variance represents the differences between the means of the different groups being compared. It measures how much the group means vary from each other. If there are significant differences between group means, this indicates that the treatment or factor being studied has an effect. The larger the between-group variability compared to within-group variability, the more likely it is that the groups are truly different and that the factor being tested has an effect.\n",
    "\n",
    "2. Within-Group Variability (Error Variability):\n",
    "This component of variance represents the variability within each group. It reflects the natural variability or \"noise\" that is inherent within any group of measurements. It includes individual differences, measurement error, and any other sources of variability that are not explained by the factors being studied. Small within-group variability indicates that the measurements within each group are relatively consistent, making it easier to detect meaningful differences between the group means.\n",
    "\n",
    "* Total Variability = Between-Group Variability + Within-Group Variability\n",
    "\n",
    "The ratio of between-group variability to within-group variability is used to calculate the F-statistic in ANOVA. This F-statistic is then compared to a critical value to determine whether the differences between group means are statistically significant.\n",
    "\n",
    "* Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "1. Interpretation: It helps researchers interpret the relative contributions of different sources of variation to the overall results. It allows us to discern whether the observed differences between groups are likely due to the factors being studied or are merely a result of random variability.\n",
    "\n",
    "2. Hypothesis Testing: ANOVA is a hypothesis testing method, and the partitioning of variance provides a structured way to test whether the differences between groups are statistically significant. By comparing the explained variance (between-group variability) to the unexplained variance (within-group variability), we can assess whether the observed differences are likely due to the factor being tested.\n",
    "\n",
    "3. Effect Size: The partitioning of variance allows us to calculate effect sizes, which quantify the practical significance of the differences between groups. This is important for understanding the practical implications of the research findings.\n",
    "\n",
    "4. Study Design: Understanding how variance is partitioned can guide the design of future studies. For example, if most of the variability is coming from within-group differences, it might suggest that the experimental conditions need to be refined to reduce noise and increase the power of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d0464-27ff-4a23-80b3-6ceffc8652fa",
   "metadata": {},
   "source": [
    "## Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00270a77-72a1-4abe-aa8b-53b1c8ea2eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 1600.4000000000003\n",
      "Explained Sum of Squares (SSE): 1478.8000000000002\n",
      "Residual Sum of Squares (SSR): 121.60000000000014\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for each group\n",
    "group1 = np.array([12, 15, 14, 18, 20])\n",
    "group2 = np.array([25, 28, 22, 24, 30])\n",
    "group3 = np.array([40, 42, 38, 36, 44])\n",
    "\n",
    "# Combine data from all groups\n",
    "all_data = np.concatenate((group1, group2, group3))\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - overall_mean) ** 2)\n",
    "\n",
    "# Calculate the Group Means\n",
    "group_means = np.array([np.mean(group1), np.mean(group2), np.mean(group3)])\n",
    "\n",
    "# Explained Sum of Squares (SSE)\n",
    "sse = np.sum((group_means - overall_mean) ** 2 * len(group1))\n",
    "\n",
    "# Residual Sum of Squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618f05c-88ac-41dc-89c9-8139ff536d31",
   "metadata": {},
   "source": [
    "## Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53078e2-029d-41f2-8f83-a3ed22b2e4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect A: 37.49999999999997\n",
      "Main Effect B: 30.333333333333336\n",
      "Interaction Effect: 1321.1666666666665\n",
      "\n",
      "F-Statistic Main A: 2.7239709443099254\n",
      "F-Statistic Main B: 1.1016949152542375\n",
      "F-Statistic Interaction: 47.98426150121065\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "# Let's assume we have a 2x3 design with two factors (A and B)\n",
    "# and the data for the dependent variable is stored in a 2D array\n",
    "data = np.array([[10, 12, 15],\n",
    "                 [14, 18, 20]])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate the column (factor A) means\n",
    "factor_a_means = np.mean(data, axis=1)\n",
    "\n",
    "# Calculate the row (factor B) means\n",
    "factor_b_means = np.mean(data, axis=0)\n",
    "\n",
    "# Calculate the grand mean of all data points\n",
    "grand_mean = np.mean(factor_a_means)\n",
    "\n",
    "# Calculate the main effect of factor A\n",
    "main_effect_a = np.sum((factor_a_means - grand_mean) ** 2) * len(factor_b_means)\n",
    "\n",
    "# Calculate the main effect of factor B\n",
    "main_effect_b = np.sum((factor_b_means - grand_mean) ** 2) * len(factor_a_means)\n",
    "\n",
    "# interaction effect\n",
    "interaction_effect = np.sum((data - (factor_a_means[:, np.newaxis] + factor_b_means)) ** 2)\n",
    "\n",
    "# residual sum of squares\n",
    "residual_sum_of_squares = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "# total sum of squares\n",
    "total_sum_of_squares = main_effect_a + main_effect_b + interaction_effect + residual_sum_of_squares\n",
    "\n",
    "# Degrees of freedom\n",
    "df_main_a = len(factor_a_means) - 1\n",
    "df_main_b = len(factor_b_means) - 1\n",
    "df_interaction = df_main_a * df_main_b\n",
    "df_residual = np.prod(data.shape) - 1\n",
    "df_total = np.prod(data.shape) - 1\n",
    "\n",
    "# Calculate the mean squares\n",
    "ms_main_a = main_effect_a / df_main_a\n",
    "ms_main_b = main_effect_b / df_main_b\n",
    "ms_interaction = interaction_effect / df_interaction\n",
    "ms_residual = residual_sum_of_squares / df_residual\n",
    "\n",
    "# Calculate the F-statistics\n",
    "f_statistic_main_a = ms_main_a / ms_residual\n",
    "f_statistic_main_b = ms_main_b / ms_residual\n",
    "f_statistic_interaction = ms_interaction / ms_residual\n",
    "\n",
    "print(\"Main Effect A:\", main_effect_a)\n",
    "print(\"Main Effect B:\", main_effect_b)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n",
    "print(\"\\nF-Statistic Main A:\", f_statistic_main_a)\n",
    "print(\"F-Statistic Main B:\", f_statistic_main_b)\n",
    "print(\"F-Statistic Interaction:\", f_statistic_interaction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96208c15-86b6-485f-b9e6-9a6d8feffcda",
   "metadata": {},
   "source": [
    "## Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d83c5-4664-4963-844b-3891ce296874",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of the groups are equal. A low p-value indicates that we have evidence to reject the null hypothesis. Let's interpret the given results:\n",
    "\n",
    "* F-Statistic of 5.23: The F-statistic is a measure of the ratio of variability between group means to the variability within the groups. A larger F-statistic indicates that the differences between group means are relatively larger compared to the within-group variability.\n",
    "\n",
    "* p-value of 0.02: The p-value is the probability of obtaining results as extreme as the ones observed in our sample, assuming that the null hypothesis is true. A p-value of 0.02 means that there's a 2% chance of observing such extreme differences between group means if there were no actual differences (assuming the null hypothesis is true).\n",
    "\n",
    "Based on these results:\n",
    "\n",
    "Since the p-value (0.02) is below the conventional threshold of significance (e.g., 0.05), So we  have evidence to reject the null hypothesis.\n",
    "\n",
    "This suggests that there are statistically significant differences between at least two of the groups you're comparing.\n",
    "The F-statistic (5.23) being relatively large supports the idea that the variation between group means is larger than the variation within the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd80c3d9-6397-46f7-9111-fc276ee634a2",
   "metadata": {},
   "source": [
    "## Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bf0f8-af71-4821-bdad-f45186eb38c9",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is important to ensure the accuracy and validity of our results. Repeated measures ANOVA involves analyzing data from the same subjects across multiple time points or conditions. There are various methods to handle missing data, each with its own implications:\n",
    "\n",
    "1. Maximum Likelihood Estimation (MLE): MLE is used in some statistical software packages to estimate parameters while accounting for missing data. MLE approaches aim to find parameter estimates that maximize the likelihood of observing the available data, given the model.\n",
    "\n",
    "2. Listwise Deletion (Complete Case Analysis): This method involves excluding any participant who has missing data on any of the time points or conditions. While this is a straightforward approach, it can lead to reduced sample size, loss of statistical power, and potential bias if missingness is related to some underlying characteristic.\n",
    "\n",
    "3. Pairwise Deletion (Available Case Analysis): Missing data for specific time points or conditions are excluded only for the calculations involving those time points or conditions. This approach retains more data than listwise deletion but can still result in bias and reduced statistical power.\n",
    "\n",
    "4. Imputation: Imputation involves estimating missing values based on observed data. Common imputation methods include mean imputation, regression imputation. Imputation can introduce bias if the imputed values do not accurately reflect the true values, and it can also underestimate the variability of the data.\n",
    "\n",
    "5. Model-Based Methods: These methods involve using statistical models to account for missing data while estimating parameters. Methods like mixed-effects models can incorporate both fixed effects (e.g., treatment effects) and random effects (e.g., subject-specific effects), which can help handle missing data more robustly.\n",
    "\n",
    "* The potential consequences of using different methods to handle missing data include:\n",
    "\n",
    "1. Bias: Incorrect handling of missing data can lead to biased parameter estimates. For instance, listwise deletion can lead to bias if missing data are related to the dependent variable.\n",
    "\n",
    "2. Loss of Power: Deleting cases with missing data or using less accurate imputation methods can lead to reduced statistical power, making it harder to detect true effects.\n",
    "\n",
    "3. Inaccurate Variability Estimates: Improper handling of missing data can result in underestimated variability, affecting the accuracy of p-values and confidence intervals.\n",
    "\n",
    "4. Invalid Results: Using improper methods can lead to incorrect conclusions, especially if the handling of missing data is not appropriately accounted for in the statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bba0f-7560-453f-8e5d-95d9011754ec",
   "metadata": {},
   "source": [
    "## Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acb82e-4874-4523-bf1f-e739f349e1eb",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after performing an analysis of variance (ANOVA) to determine which specific group means are significantly different from each other when the ANOVA indicates a significant overall effect. They help to identify pairwise differences between groups when there are three or more groups being compared. Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD): Tukey's HSD test is often used when we have equal group sizes and we want to compare all possible pairwise group means. It controls the familywise error rate, making it suitable for multiple comparisons.\n",
    "\n",
    "2. Bonferroni Correction: The Bonferroni correction is a conservative method that adjusts the significance level for each pairwise comparison to maintain an overall desired familywise error rate. It's suitable when we want to control the risk of making a Type I error in multiple comparisons.\n",
    "\n",
    "3. Dunn's Test: Dunn's test is a non-parametric alternative to Tukey's HSD. It's used when the assumptions of normality and homoscedasticity are not met.\n",
    "\n",
    "4. Scheffé Test: The Scheffé test is more conservative than Tukey's HSD and is used when the assumptions of equal variances and normality are not met. It provides wider confidence intervals for pairwise differences.\n",
    "\n",
    "5. Fisher's LSD (Least Significant Difference): Fisher's LSD test is less conservative than Tukey's HSD and is appropriate when we have equal variances and normality. However, it doesn't control the familywise error rate as effectively as Tukey's HSD.\n",
    "\n",
    "* Example situation where a post-hoc test might be necessary:\n",
    "\n",
    "Let's say we have conducted a one-way ANOVA to compare the performance of students from three different schools based on their test scores. The ANOVA indicates a significant overall effect, suggesting that there are differences in performance among the schools. However, the ANOVA doesn't tell us which specific pairs of schools are significantly different from each other.\n",
    "\n",
    "In this case, we would use a post-hoc test to perform pairwise comparisons between the schools. For instance, we might apply Tukey's HSD test to determine which school pairs have significantly different mean test scores. This would help we identify if one school's students are performing better or worse compared to others and provide more detailed insights into the differences among the schools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823f206-66d8-4c2b-a67e-04c2592deab9",
   "metadata": {},
   "source": [
    "## Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef0d6da-1a3a-41f8-98d7-e9327fdfa0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 292.76362425049905\n",
      "p-value: 2.6246698882540166e-35\n",
      "There are significant differences in the mean weight loss among the diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Simulated weight loss data for each diet\n",
    "diet_A = np.array([3.5, 2.8, 4.2, 5.1, 2.3, 3.9, 4.7, 2.6, 3.8, 4.0,\n",
    "                   2.5, 4.5, 3.2, 4.8, 3.7, 2.9, 4.1, 3.3, 4.6, 3.0,\n",
    "                   2.7, 3.4, 4.9, 3.6, 4.3])\n",
    "diet_B = np.array([2.0, 1.8, 1.5, 2.5, 1.2, 1.9, 1.4, 1.6, 2.1, 1.7,\n",
    "                   2.3, 1.3, 2.2, 1.1, 1.8, 2.4, 1.9, 1.6, 2.0, 1.5,\n",
    "                   2.5, 1.2, 1.7, 2.1, 1.4])\n",
    "diet_C = np.array([5.8, 6.2, 5.0, 5.5, 6.0, 5.3, 5.9, 5.7, 6.4, 5.6,\n",
    "                   5.2, 6.1, 5.4, 6.3, 5.8, 6.2, 5.1, 5.9, 6.0, 5.5,\n",
    "                   5.6, 5.3, 5.7, 6.4, 5.6])\n",
    "\n",
    "# Combine all data\n",
    "all_data = np.concatenate((diet_A, diet_B, diet_C))\n",
    "\n",
    "# Create labels for each diet for performing ANOVA test\n",
    "labels = np.array(['A'] * len(diet_A) + ['B'] * len(diet_B) + ['C'] * len(diet_C))\n",
    "\n",
    "# Perform one-way ANOVA test\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpretation of the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There are significant differences in the mean weight loss among the diets.\")\n",
    "else:\n",
    "    print(\"There are no significant differences in the mean weight loss among the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988510d-3061-4316-9499-0332bb540f02",
   "metadata": {},
   "source": [
    "## Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc40827-5a59-419e-a0c4-400b5e7c71af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              sum_sq    df         F    PR(>F)\n",
      "C(Software)                 1.035327   2.0  0.136986  0.872659\n",
      "C(Experience)               0.521940   1.0  0.138118  0.713420\n",
      "C(Software):C(Experience)   2.683910   2.0  0.355113  0.704716\n",
      "Residual                   90.694755  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Simulated data\n",
    "np.random.seed(42)\n",
    "n = 30\n",
    "software = np.random.choice(['A', 'B', 'C'], n)\n",
    "experience = np.random.choice(['Novice', 'Experienced'], n)\n",
    "time = np.random.normal(loc=10, scale=2, size=n)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Software': software, 'Experience': experience, 'Time': time})\n",
    "\n",
    "# Fit a two-way ANOVA model with interaction\n",
    "model = ols('Time ~ C(Software) * C(Experience)', data=data).fit()\n",
    "\n",
    "# Perform ANOVA analysis\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3076f2-bdf4-4636-9dbc-5d6fdf80172f",
   "metadata": {},
   "source": [
    "* Interpreting the results:\n",
    "\n",
    "1. A p-value less than the chosen significance level (e.g., 0.05) indicates that the effect is statistically significant.\n",
    "\n",
    "2. If the p-value is significant for the Software factor, it suggests that there are significant differences in task completion times between different software programs.\n",
    "\n",
    "3. If the p-value is significant for the Experience factor, it suggests that there are significant differences in task completion times between novice and experienced employees.\n",
    "\n",
    "4. If the p-value is significant for the Software:Experience interaction term, it indicates that the effect of one factor depends on the level of the other factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2b4ce-0363-4d16-a6d7-708c33225051",
   "metadata": {},
   "source": [
    "## Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be5f023-19dd-453d-b2e1-9ed720e4c059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "T-Statistic: -1.5267455833477102\n",
      "p-value: 0.13004538960951503\n",
      "\n",
      "The p-value is not significant, so no post-hoc test is needed here.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Simulated test scores for the control and experimental groups\n",
    "np.random.seed(0)\n",
    "control_group = np.random.normal(loc=75, scale=10, size=50)\n",
    "experimental_group = np.random.normal(loc=80, scale=12, size=50)\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test if results are significant\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nSince the p-value is significant, we need to perform a post-hoc test.\")\n",
    "    posthoc = pairwise_tukeyhsd(np.concatenate((control_group, experimental_group)),\n",
    "                                 np.concatenate((['Control'] * 50, ['Experimental'] * 50)),\n",
    "                                 alpha=0.05)\n",
    "    print(posthoc)\n",
    "else:\n",
    "    print(\"\\nThe p-value is not significant, so no post-hoc test is needed here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c3970-a27e-4508-ae84-77a4095af530",
   "metadata": {},
   "source": [
    "## Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd85f91-8d67-4ecd-b6a6-cee00b928c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA Results:\n",
      "F-Statistic: 0.8647116816086053\n",
      "p-value: 0.4247606893565754\n",
      "\n",
      "The p-value is not significant, so no post-hoc test is needed here .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Randomly Simulated daily sales data for three stores\n",
    "np.random.seed(0)\n",
    "store_A_sales = np.random.normal(loc=1000, scale=200, size=30)\n",
    "store_B_sales = np.random.normal(loc=1100, scale=180, size=30)\n",
    "store_C_sales = np.random.normal(loc=1050, scale=190, size=30)\n",
    "\n",
    "# Combine the sales data\n",
    "all_sales = np.concatenate((store_A_sales, store_B_sales, store_C_sales))\n",
    "\n",
    "# Create labels for the groups\n",
    "store_labels = np.array(['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(store_A_sales, store_B_sales, store_C_sales)\n",
    "\n",
    "print(\"One-Way ANOVA Results:\")\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test if results are significant\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nSince the p-value is significant, we need to perform a post-hoc test.\")\n",
    "    posthoc = pairwise_tukeyhsd(all_sales, store_labels, alpha=0.05)\n",
    "    print(posthoc)\n",
    "else:\n",
    "    print(\"\\nThe p-value is not significant, so no post-hoc test is needed here .\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
